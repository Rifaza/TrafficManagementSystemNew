# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AFKyOmBbKcrgEk2P4DZEzgULXaQriT4U
"""
from sklearn.tree import DecisionTreeRegressor
import numpy as np
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
pd.plotting.register_matplotlib_converters()
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

# from google.colab import files
# uploaded = files.upload()

import io
df1 = pd.read_csv("/home/rifaza/Final_Year_Project/Spartans/Transportation/aqi.csv")
df1.head()

from sklearn.model_selection import train_test_split
features=['Time_GMT','AQI']
X=df1[features]
y=df1.ROC
train_X, test_X, train_y, test_y = train_test_split(X, y,test_size=0.2)

from sklearn.metrics import mean_absolute_error
from sklearn.linear_model import LinearRegression
regressor = LinearRegression(n_jobs=-1)
regressor.fit(train_X, train_y)
pred_y=regressor.predict(test_X)
mae = mean_absolute_error(test_y, pred_y)
print(mae)

from sklearn.ensemble import RandomForestRegressor

forest_model = RandomForestRegressor(random_state=42,n_estimators=100,n_jobs=11)
forest_model.fit(train_X, train_y)
melb_preds = forest_model.predict(test_X)
print(mean_absolute_error(test_y, melb_preds))

from sklearn.tree import DecisionTreeRegressor

DecisionTreeRegressor_model = DecisionTreeRegressor(max_leaf_nodes=1000, random_state=42,)
DecisionTreeRegressor_model.fit(train_X, train_y)
preds_val = DecisionTreeRegressor_model.predict(test_X)
mae = mean_absolute_error(test_y, preds_val)
print(mae)
import pickle
from sklearn.externals import joblib
filename = 'train_AQHI_Changing_Rate_by_DecisionTree.pkl'
joblib.dump(DecisionTreeRegressor_model, filename)


# first neural network with keras tutorial
from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense

# define the keras model
keras_model = Sequential()
keras_model.add(Dense(4, input_dim=2, activation='relu'))
keras_model.add(Dense(4, activation='relu'))
keras_model.add(Dense(1, activation='sigmoid'))
# compile the keras model
keras_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
keras_model.fit(train_X, train_y, epochs=20, batch_size=24)
# evaluate the keras model
val=keras_model.predict(test_X)
mae = mean_absolute_error(test_y, val)
print(mae)

all_y=DecisionTreeRegressor_model.predict(X)
all_y

x_time=X['Time_GMT'][:24]
Y_aqi=all_y[:24]

plt.figure(figsize=(10,6))

# Add title
plt.title("Average AQI changing rate for the day, by time")

# Bar chart showing average arrival delay for Spirit Airlines flights by month
sns.barplot(x=x_time, y=Y_aqi)

# Add label for vertical axis
plt.ylabel("AQI changing rate")
plt.xlabel("time")
plt.show()
features_new=['Time_GMT', 'AQI','predicted_aqi', 'next_hour_aqi']
x_new=df1[features_new]
y_new=df1.classification
train_x_new, test_x_new, train_y_new, test_y_new = train_test_split(x_new, y_new,test_size=0.2)

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

models = []
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC(gamma='auto')))
models.append(('decision tree',DecisionTreeClassifier(criterion="entropy", max_depth=3)))
#DecisionTreeClassifier(criterion="entropy", max_depth=3)
# evaluate each model in turn
results = []
names = []
for name, model in models:
	kfold = StratifiedKFold(n_splits=10, )
	cv_results = cross_val_score(model, train_x_new, train_y_new, cv=kfold, scoring='accuracy')
	results.append(cv_results)
	names.append(name)
	print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))

from sklearn.tree import DecisionTreeClassifier

DecisionTreeClassifier_model = DecisionTreeClassifier(criterion="entropy", max_depth=3)
DecisionTreeClassifier_model.fit( train_x_new, train_y_new)
preds_val_new = DecisionTreeClassifier_model.predict(test_x_new)
mae = mean_absolute_error(test_y_new, preds_val_new)
print(mae)

preds_level=DecisionTreeClassifier_model.predict(x_new)
preds_level


filename = 'mdl4.pkl'
joblib.dump(DecisionTreeClassifier_model, filename)

#def predict_roc(time,aqi):
#  sample_test=[time,aqi],[time,aqi]
#  predcited_roc=DecisionTreeRegressor_model.predict(sample_test)
# #print(predcited_roc[0])
 # return predcited_roc[0]

def predict_level(time,aqi):
  sample_test=[time,aqi],[time,aqi]

  predicted_aqi_roc=DecisionTreeRegressor_model.predict(sample_test)
  roc=predicted_aqi_roc[0]
  print("predicted rate of change of AQI= ",roc)
  next_hour=aqi+roc
  test_sample=([time,aqi,roc,next_hour],[time,aqi,roc,next_hour])
  predicted_level=DecisionTreeClassifier_model.predict(test_sample)
  if(predicted_level[0]==0):
    print("for next hour, situation of the Road is bad!")
  else:
    print("for the next hour, situation of the Road is ok!")
predict_level(0,22)